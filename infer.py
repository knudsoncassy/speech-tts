scripts/infer.py (GPU-accelerated inference with speak())
from pathlib import Path from TTS.api import TTS MODELS_DIR = Path(__file__).resolve().parent.parent / "models" / "checkpoints" OUTPUT_DIR = Path(__file__).resolve().parent.parent / "output" OUTPUT_DIR.mkdir(exist_ok=True) def load_model(): ckpt = MODELS_DIR / "best_model.pth.tar" if ckpt.exists(): print("[+] Loading fine-tuned model on GPU...") return TTS(model_path=str(ckpt), gpu=True) else: print("[!] No fine-tuned model found. Falling back to pretrained (GPU).") return TTS("tts_models/en/ljspeech/tacotron2-DDC", gpu=True) tts = load_model() def speak(text: str, out_path: str = None): """Generate speech from text using the trained or fallback model.""" if out_path is None: out_path = OUTPUT_DIR / "output.wav" tts.tts_to_file(text=text, file_path=str(out_path)) print(f"[+] Audio saved to {out_path}") return str(out_path) if __name__ == "__main__": speak("GPU accelerated voice model is now speaking.")
